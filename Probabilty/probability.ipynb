{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/globalaihub/introduction-to-machine-learning/blob/main/Probabilty/probability.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ii6SZ-Urv_QC"
   },
   "source": [
    "![](img/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XT3n8LW2v_QD"
   },
   "source": [
    "<h5><center>All rights reserved ©️ Global AI Hub 2020</center></h5> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtuZFrxtv_QE"
   },
   "source": [
    "# Probability Review\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxybYIfjv_QE"
   },
   "source": [
    "Probability is the branch of mathematics concerning numerical descriptions of how likely an event is to occur, or how likely it is that a proposition is true. The probability of an event is a number between 0 and 1, where, roughly speaking, 0 indicates impossibility of the event and 1 indicates certainty. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXHonzRLv_QF"
   },
   "source": [
    "##  Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWcCllckv_QF"
   },
   "source": [
    "A random variable is a variable that can take on diﬀerent values randomly. We typically denote the random variable itself with a lowercase letter in plain typeface, and the values it can take on with lowercase script letters. For example, x1 and x2 are both possible values that the random variable x can take on. For vector-valued variables, we would write the random variable as x and one of its values as x. On its own, a random variable is just a description of the states that are possible; it must be coupled with a probability distribution that speciﬁes how likely each of these states are. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGyrELttv_QF"
   },
   "source": [
    "Random variables may be discrete or continuous. A discrete random variable is one that has a ﬁnite or countably infinite number of states. Note that these states are not necessarily the integers; they can also just be named states that are not considered to have any numerical value. A continuous random variable is associated with a real value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94UfigFgv_QG"
   },
   "source": [
    "## Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pvg9bB81v_QG"
   },
   "source": [
    "A probability distributionis a description of how likely a random variable or set of random variables is to take on each of its possible states. The way we describe probability distributions depends on whether the variables are discrete or continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Go2MuuxPv_QH"
   },
   "source": [
    "![Prob](img/1.png)                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Prob](img/histogram.png)\n",
    " <h5><center>Continuous Variable - Histogram (No Gap)</center></h5>      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/bar2.png)\n",
    " <h5><center>Discrete Variable - Bar Graph</center></h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIgRi-sFv_QI"
   },
   "source": [
    "### Discrete Variables and Probability Mass Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sG9RAchlv_QI"
   },
   "source": [
    "A probability distribution over discrete variables can be explained using a probability mass function (PMF). We typically express probability mass functions with a capital P. Usually, we associate each random variable with a different probability mass function, and the reader must determine which PMF to use based on the identity of the random variable instead of the name of the function; P (x) is generally not the same as P (y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Prob](img/dis2.png)\n",
    " <h5><center>Probability Mass Function</center></h5>         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNTwrtSNv_QJ"
   },
   "source": [
    "### Continuous Variables and Probability Density Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ms0drg0hv_QJ"
   },
   "source": [
    "When working with continuous random variables, we describe probability distributions using a probability density function (PDF) rather than a probability mass function. To be a probability density function, a function p must satisfy the following properties:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdrk1T9_v_QK"
   },
   "source": [
    "1. The domain of p must be the set of all possible states of x\n",
    "2. ∀x ∈ x, p(x) ≥ 0. Note that we do not require $p(x)\\leq1$\n",
    "3. $\\int_a^bp(x)dx = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Prob](img/cont1.jpg)\n",
    " <h5><center>PDF</center></h5>       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Prob](img/overview-prob-distr.png)\n",
    " <h5><center>Types of Probabilty Distributions</center></h5>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Disc](img/disc.PNG)\n",
    " <h5><center>Discrete Distributions</center></h5>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Con](img/cont.PNG)\n",
    " <h5><center>Countinous Distributions</center></h5>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBwKOZJjv_QK"
   },
   "source": [
    "## Marginal & Conditional Prob."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqkMsDRxv_QK"
   },
   "source": [
    "### Marginal Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of one event in the presence of all (or a subset of) outcomes of the other random variable is called the marginal probability or the marginal distribution. The marginal probability of one random variable in the presence of additional random variables is referred to as the marginal probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_k47V_Lv_QL"
   },
   "source": [
    " <h2><center> $P(X=A) = \\sum_{i} P(X=A, Y=yi)$ for all Y</center></h2>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/mar_prob.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nikQKlFov_QM"
   },
   "source": [
    "### Conditional Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDnE6ng2v_QM"
   },
   "source": [
    "The probability of one event given the occurrence of another event is called the *conditional probability*. The conditional probability of one to one or more random variables is referred to as the conditional probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qGGdCbOv_QN"
   },
   "source": [
    " <h2><center>P(A given B) = P(A | B)</center></h2>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/cond.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnMS5VHZv_QN"
   },
   "source": [
    "## Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PspPmXhIv_QN"
   },
   "source": [
    "If one variable is not dependent on a second variable, this is called *independence* or *statistical independence*. For example, we may be interested in the joint probability of independent events A and B, which is the same as the probability of A and the probability of B.\n",
    "\n",
    "Probabilities are combined using multiplication, therefore the joint probability of independent events is calculated as the probability of event A multiplied by the probability of event B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_bfibLxv_QO"
   },
   "source": [
    "<h2><center>P(A and B) = P(A) * P(B)</center></h2>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-Ey-Okqv_QO"
   },
   "source": [
    "## Expectation, Variance, Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3-ybw0pv_QP"
   },
   "source": [
    "### Expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCdKv7l7v_QP"
   },
   "source": [
    "The expectation, or expected value, of some function f(x) with respect to a probability distribution P(x) is the average, or mean value, that f takes on when x is drawn from P. For discrete variables this can be computed with a summation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkTPlaYlv_QP"
   },
   "source": [
    "<h1><center>$\\mathrm{E[x]}=\\sum_{n=a}^{b}P(x)f(x)$</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1uvuv-Uv_QQ"
   },
   "source": [
    "while for continuous variables, it is computed with an integral:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5m7Y6DYNv_QQ"
   },
   "source": [
    "<h1><center>$\\mathrm{E[x]}=\\int_a^bP(x)f(x)dx$</center></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIP-7_H_v_QR"
   },
   "source": [
    "### Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qtk6rkZgv_QR"
   },
   "source": [
    "The variance gives a measure of how much the values of a function of a random variable x vary as we sample diﬀerent values of x from its probability distribution. It measures how far a set of numbers is spread out from their average value:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLSSJ6OGv_QR"
   },
   "source": [
    "<h1><center>$\\mathrm{Var[x]}= \\mathrm{E[(x-\\mathrm{E[x]})^2]}$</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyVcGE3sv_QS"
   },
   "source": [
    "When the variance is low, the values of f(x) cluster near their expected value. The Square root of the variance is known as the *standard deviation*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/std.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsOWKwInv_QS"
   },
   "source": [
    "### Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hi96QNs-v_QT"
   },
   "source": [
    "In probability, covariance is the measure of the joint probability for two random variables. It describes how the two variables change together.\n",
    "\n",
    "It is denoted as the function cov(X, Y), where X and Y are the two random variables being considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OABR2Q74v_QT"
   },
   "source": [
    "<h1><center>$\\mathrm{Cov[x,y]}=\\mathrm{E[(x-\\mathrm{E[x]})(y-\\mathrm{E[y]})]}$</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6qt5FFMv_QU"
   },
   "source": [
    "## Bayes' Rule "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47SaOhn_v_QU"
   },
   "source": [
    "In probability theory and statistics, Bayes's theorem (alternatively Bayes's law or Bayes's rule) describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For example, if the risk of developing health problems is known to increase with age, Bayes's theorem allows the risk to an individual of a known age to be assessed more accurately than simply assuming that the individual is typical of the population as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saCaM_Vfv_QU"
   },
   "source": [
    "We often ﬁnd ourselves in a situation where we know P(y | x) and need to know P(x | y). Fortunately, if we also know P(x), we can compute the desired quantity using Bayes’ rule:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/Bayes_theorem_1.png)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "probability.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
